# üìÇ Proyecto MLOps ‚Äî Absenteeism at Work (Team 6)

Este repositorio contiene el proyecto de la asignatura de **MLOps**, utilizando el dataset *Absenteeism at Work*.  
El objetivo es aplicar pr√°cticas de versionado de datos, exploraci√≥n, limpieza y modelado de Machine Learning en equipo.

---

## üöÄ Setup del entorno

### 1. Clonar el repositorio
```bash
git clone https://github.com/vbravo-tec/mlops-absenteeism-team6.git
cd mlops-absenteeism-team6
``` 
### 2. Crear y activar entorno virtual
```bash
python -m venv .venv
.\.venv\Scripts\Activate.ps1
``` 

### 3. Instalar dependencias
```bash
pip install --upgrade pip
pip install -r requirements.txt

``` 
### 4. Congelar dependencias (solo si instalas algo nuevo)
```bash
pip freeze > requirements.lock.txt

```
##  Estructura de datos (DVC)

El versionado de datos se realiza con DVC.
Los datasets NO se suben a GitHub, solo los punteros .dvc.

Carpetas principales:

data/
 ‚îú‚îÄ‚îÄ raw/        <- Datos originales y modificados (provistos por TA)
 ‚îú‚îÄ‚îÄ interim/    <- Datos intermedios (limpieza parcial, imputaci√≥n, etc.)
 ‚îú‚îÄ‚îÄ processed/  <- Datos finales listos para modelado
 ‚îî‚îÄ‚îÄ external/   <- Datos de terceros (si se integran fuentes adicionales)

Ejemplo de datasets actuales:
data/raw/Absenteeism_at_work_original.csv
data/raw/Absenteeism_at_work_modificado.csv

##  Remote de DVC (Google Drive)
El almacenamiento remoto est√° configurado en Google Drive.
Cada integrante debe ejecutar una sola vez:
```bash
dvc pull
```
Pasos al correr `dvc pull` por primera vez:
1. Se abrir√° el navegador con la ventana de autenticaci√≥n de Google.
2. Inicia sesi√≥n con tu correo institucional (el que fue autorizado).
3. Acepta los permisos.
4. DVC almacenar√° el token localmente (no se versiona).

##  Flujo de trabajo con datos

### 1. Obtener datasets

```bash
git pull origin main
dvc pull
```

### 2. Crear nuevas versiones (ejemplo limpieza)

```bash
# generar dataset limpio en data/interim/
python mlops/dataset.py --task clean \
    --input data/raw/work_absenteeism_modified.csv.csv \
    --output data/interim/absenteeism_clean_v1.csv

# versionar con DVC
dvc add data/interim/absenteeism_clean_v1.csv
git add data/interim/absenteeism_clean_v1.csv.dvc
git commit -m "data(interim): primera versi√≥n de limpieza"
dvc push
git push origin <mi-rama>

```
### 3. Reproducir pipeline
```bash
dvc repro

```

## Convenciones del equipo

- **Ramas**:  
  - Crear **una rama por tarea**  
    Ejemplos:  
    - `data/cleaning-nulos`  
    - `features/encoding`  
    - `model/baseline-logreg`  
  - Nunca trabajar directamente en `main`.

- **Merge a main**:  
  - Solo v√≠a **Pull Request (PR)**.  
  - Cada PR debe incluir descripci√≥n clara de los cambios.

- **No subir datos a GitHub**:  
  - Todos los datasets deben versionarse con **DVC**.  
  - Usar siempre:  
    ```bash
    dvc add <archivo>
    dvc push
    git add <archivo>.dvc
    git commit -m "data(...): descripci√≥n"
    git push origin <mi-rama>
    ```

- **params.yaml**:  
  - Editar par√°metros de limpieza, features, split y modelos aqu√≠.  
  - **Nunca** hardcodear valores en los scripts.

- **main protegido**:  
  - No se permiten commits directos.  
  - Solo se actualiza mediante **PR revisados y aprobados**.

## üë• Roles y responsabilidades del equipo

| Rol                | GitHub User   | Responsabilidades principales |
|--------------------|--------------|--------------------------------|
| **DevOps / SRE**   | @vbravo-tec  | Configuraci√≥n de CI/CD, versionado con DVC, pipelines (`dvc.yaml`, `params.yaml`), mantenimiento de infraestructura del repo. |
| **Data Scientist** | @A01795943   | An√°lisis exploratorio (EDA), creaci√≥n y validaci√≥n de features (`mlops/features.py`), experimentaci√≥n en notebooks. |
| **Data Engineer**  | @Joelrbtec   | Limpieza de datos, imputaci√≥n, gesti√≥n de datasets (`mlops/dataset.py`, `/data/`), asegurar calidad de los datos. |
| **ML Engineer**    | @Mike        | Construcci√≥n, entrenamiento y evaluaci√≥n de modelos (`mlops/modeling/`), ajuste de hiperpar√°metros, m√©tricas. |

üìå Todas las tareas deben hacerse en **ramas espec√≠ficas por tarea** y ser integradas v√≠a **Pull Request**.  
üìå GitHub solicitar√° revisi√≥n autom√°tica de acuerdo a este rol, gracias a la configuraci√≥n en el archivo `CODEOWNERS`.


## üîÑ Flujo de Trabajo del Equipo

```mermaid
flowchart TD
    A[Crear rama de trabajo] --> B[Commit y push]
    B --> C[Pull request hacia main]

    C --> D{CODEOWNERS asigna revisores}
    D --> DS[Data Scientist]
    D --> DE[Data Engineer]
    D --> MLE[ML Engineer]
    D --> SRE[DevOps SRE]

    DS --> E[Aprobacion]
    DE --> E
    MLE --> E
    SRE --> E

    E --> F[CI valida lint y tests]
    F -->|OK| G[Merge a main]
    F -->|Error| H[Correcciones en la rama]

---

üìå **C√≥mo leerlo:**  
1. Cada integrante trabaja en su rama (`data/...`, `features/...`, etc.).  
2. Al abrir un **Pull Request**, GitHub asigna autom√°ticamente revisores seg√∫n `CODEOWNERS`.  
3. El equipo revisa y aprueba ‚Üí corre el **CI/CD**.  
4. Si pasa, se hace merge a `main`.  

---

## üîÑ Flujo de Trabajo con DVC Integrado

```mermaid
flowchart TD
    subgraph Dev [Desarrollo en ramas]
        A[Crear rama de trabajo] --> B[Commit y push]
        B --> C[Pull request hacia main]
    end

    subgraph Revision [Revision por roles]
        C --> D{CODEOWNERS asigna revisores}
        D --> DS[Data Scientist]
        D --> DE[Data Engineer]
        D --> MLE[ML Engineer]
        D --> SRE[DevOps SRE]
        DS --> E[Aprobacion]
        DE --> E
        MLE --> E
        SRE --> E
    end

    subgraph CI [CI y DVC]
        E --> F[CI valida lint y tests]
        F --> G{Pipeline DVC}
        G --> H[Datos en Google Drive]
        G --> I[Outputs reproducibles en data y models]
        G --> J[Parametros en params.yaml]
    end

    G --> K[PR listo para merge]
    F -->|Error| L[Correcciones en la rama]
    K --> M[Merge a main]


---

üìå **Explicaci√≥n:**  
1. Cada integrante trabaja en su rama y abre un PR.  
2. Los revisores se asignan autom√°ticamente seg√∫n `CODEOWNERS`.  
3. El **CI/CD** valida que el c√≥digo cumpla con reglas y que el **pipeline de DVC** corra.  
4. DVC asegura que:  
   - Los **datos crudos y derivados** est√°n en **Google Drive (remote)**.  
   - Los **outputs** (clean, features, modelos) son reproducibles.  
   - Los **par√°metros** se controlan en `params.yaml`.  
5. Si todo pasa ‚Üí se mergea a `main`.  

---
